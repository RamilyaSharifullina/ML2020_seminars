{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/adasegroup/ML2020_seminars/blob/master/seminar10/RVMReg_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Qo1i1Rw39_F"
   },
   "source": [
    "### Toy Relevance Vector Machine (Regression) Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hmu6nKZo39_K"
   },
   "source": [
    "Course: MA06018, Machine Learning by professor [Evgeny Burnaev](mailto:e.burnaev@skoltech.ru) \n",
    "\n",
    "Author: [Evgenii Egorov](mailto:egorov.evgenyy@ya.ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bk5ORP3p39_O"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oa65cBH-39_W"
   },
   "source": [
    "We consider the following model:\n",
    "    \n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "    & p(t_n|x_n, w;\\beta) = \\mathcal{N}(t_n| \\textbf{w}^Tx_n, \\beta^{-1}), \\\\\n",
    "    & p(\\textbf{t}|X,\\textbf{w};\\beta) = \\prod\\limits_{n=1}^{N}p(t_n|x_n, \\textbf{w};\\beta) = \\mathcal{N}(\\textbf{t}|X\\textbf{w}, \\beta^{-1}), \\\\\n",
    "    & p(\\textbf{w};\\alpha) = \\prod\\limits_{d=1}^{D}\\mathcal{N}(w_d|0, \\alpha_d^{-1})=\\mathcal{N}(\\textbf{w}|0,A^{-1}).\n",
    "    \\end{aligned}\n",
    "\\end{equation*}  \n",
    "\n",
    "And for optimize the evidence we come up with the following equations:\n",
    "\n",
    "$$\n",
    "\\max\\limits_{\\alpha,\\beta}\\tfrac{N}{2}\\log\\beta+\\tfrac{1}{2}\\log|A|- \\tfrac{1}{2}\\log|\\left(\\beta X^TX+A\\right)|-\\tfrac{\\beta}{2}\\|\\textbf{t}-X\\mu\\|_2^2 -\\tfrac{1}{2}\\mu^TA\\mu.\n",
    "$$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "& \\mu^{new} = \\beta(\\beta X^T X + A)^{-1}X^T\\textbf{t},\\\\\n",
    "& \\alpha_i^{new} = \\frac{1}{\\mu^2_i}(1-\\Sigma_{ii}^{old}\\alpha_i^{old}),\\\\\n",
    "& \\beta^{new} = \\frac{1}{\\|t-X\\mu\\|_2^2}\\left(N-\\text{trace} (I-\\Sigma^{old}A^{old})\\right),\\\\\n",
    "& \\Sigma^{new} = (\\beta^{new} X^TX + A^{new})^{-1}.\\\\\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "For details and derivations please see the corresponding slides: [slides](https://drive.google.com/open?id=1ezz6LXef6pFdbljSvvZIlnmYqietQg-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huIns4q239_Y"
   },
   "source": [
    "##### Task 1.1\n",
    "Please write code at the each method <i>update_%smth%</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gewcIIn639_a"
   },
   "outputs": [],
   "source": [
    "class RVM:\n",
    "    def __init__(self, data):\n",
    "        self.X = data[0]\n",
    "        self.t = data[1]\n",
    "        \n",
    "        self.alpha = np.array([0.1] * self.X.shape[1])\n",
    "        self.beta = 1.\n",
    "        self.Sigma = None\n",
    "        \n",
    "        self.data_cov = None\n",
    "        self.data_mu = None\n",
    "        \n",
    "        self.idx_relevant = np.array(range(self.X.shape[1]))\n",
    "        \n",
    "    def data_params(self):\n",
    "        data_cov = self.X.T @ self.X\n",
    "        data_mu = self.X.T @ self.t\n",
    "        return data_cov, data_mu\n",
    "    \n",
    "    def get_sigma(self):\n",
    "        return np.linalg.inv(self.beta * self.data_cov + np.diag(self.alpha))\n",
    "    \n",
    "    @staticmethod\n",
    "    def update_mu(Sigma, beta, data_mu):\n",
    "        return beta * Sigma @ data_mu\n",
    "    \n",
    "    @staticmethod\n",
    "    def update_alpha(Sigma, beta, mu, alpha):\n",
    "        sigma_diag = np.diag(Sigma)\n",
    "        return (1 - sigma_diag * alpha) / mu ** 2\n",
    "    \n",
    "    @staticmethod\n",
    "    def update_beta(Sigma, alpha, mu, X, t):\n",
    "        N = X.shape[0]\n",
    "        sigma_diag = np.diag(Sigma)\n",
    "        return (N - np.sum(1 - sigma_diag * alpha)) / np.linalg.norm(t - X @ mu) ** 2\n",
    "    \n",
    "    def update_step(self):\n",
    "        mu = self.update_mu(self.Sigma, self.beta, self.data_mu)\n",
    "        \n",
    "        alpha = self.update_alpha(self.Sigma, self.beta, mu, self.alpha)\n",
    "        beta = self.update_beta(self.Sigma, self.alpha, mu, self.X, self.t)\n",
    "        return mu, alpha, beta\n",
    "    \n",
    "    def elbo(self):\n",
    "        N = self.X.shape[0]\n",
    "        lbound = N * np.log(self.beta) + np.sum(np.log((self.alpha))) - self.beta * np.linalg.norm(self.X @ self.mu - self.t) ** 2\\\n",
    "        - np.sum(self.mu ** 2 * self.alpha) + np.log(np.linalg.det(self.Sigma))\n",
    "        return lbound\n",
    "    \n",
    "    def prune(self, threshold):\n",
    "        idx = np.where(self.alpha < threshold)[0]\n",
    "        if len(idx) != 0:\n",
    "            bad = np.where(self.alpha >= threshold)[0]\n",
    "            temp = self.idx_relevant[np.where(self.idx_relevant != -1)] \n",
    "            temp[bad] = -1\n",
    "            self.idx_relevant[np.where(self.idx_relevant != -1)] = temp\n",
    "            \n",
    "            self.X = self.X[:, idx]\n",
    "            self.alpha = self.alpha[idx]\n",
    "            self.mu = self.mu[idx]\n",
    "            self.data_cov, self.data_mu = self.data_params()\n",
    "            \n",
    "            \n",
    "    def fit(self, prune=1e5, max_iter=10):\n",
    "        self.data_cov, self.data_mu = self.data_params()\n",
    "        \n",
    "        for i in range(max_iter):\n",
    "            self.Sigma = self.get_sigma()\n",
    "            self.mu, self.alpha, self.beta = self.update_step()\n",
    "            if prune is not None:\n",
    "                self.prune(prune)\n",
    "            else:\n",
    "                self.alpha = np.clip(self.alpha, 0., 1e5)\n",
    "            print(i, self.elbo())\n",
    "        return 0\n",
    "    \n",
    "    def get_relevant_features_prune(self):\n",
    "        return self.idx_relevant[np.where(self.idx_relevant != -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dcICjveW39_f"
   },
   "source": [
    "Let's see how it works. We generate some sparse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilHVVTtE39_g"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODTx2hQ_39_l",
    "outputId": "15cf766e-33dd-41d5-a339-560ba7a86811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         85.31226958\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  5.30679943  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         27.83489895  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n",
      "[47 72 88]\n"
     ]
    }
   ],
   "source": [
    "X, t, coef_true = make_regression(100, 100, 3, coef=True)\n",
    "print(coef_true)\n",
    "print(np.where(coef_true != 0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SBDZmLJr39_r"
   },
   "source": [
    "And now we expect that RVM will return for us exactly these non-zero features.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d28f3f0N39_s"
   },
   "outputs": [],
   "source": [
    "reg = RVM((X, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76lp80f239_w",
    "outputId": "b032d27d-1629-4d03-cd03-7c3a409259ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -724.3141089629803\n",
      "1 426.18799320264793\n",
      "2 344.17365985736717\n",
      "3 4060.2007604441797\n",
      "4 5955.054255018947\n",
      "5 5900.655921888045\n",
      "6 5909.986231921085\n",
      "7 6081.527617113769\n",
      "8 5961.464497051269\n",
      "9 5893.114340583469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbX4eUe639_1",
    "outputId": "4c3db204-cafc-4783-f8cd-18a54edeedf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 72, 88])"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.get_relevant_features_prune()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKud8R6R39_6"
   },
   "source": [
    "Eeee!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RVMReg-Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
