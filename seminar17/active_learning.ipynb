{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/adasegroup/ML2020_seminars/blob/master/seminar17/active_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SOURCES\n",
    "#\n",
    "# https://towardsdatascience.com/active-learning-tutorial-57c3398e34d\n",
    "# https://hunch.net/~active_learning/active_learning_icml09.pdf\n",
    "# https://scikit-learn.org/stable/auto_examples/semi_supervised/plot_label_propagation_digits_active_learning.html\n",
    "# https://towardsdatascience.com/uncertainty-sampling-cheatsheet-ec57bc067c0b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/adasegroup/ML2020_seminars/blob/master/seminar17/pic/pool-based-AL.jpg?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal of Active Learning**: \n",
    "    1. train the best classifier/regressor using the smallest train set\n",
    "    2. objects are queried and annotated from the pool sequentially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Active Learning Heuristic**\n",
    "\n",
    "1. Start with a pool of unlabeled data\n",
    "2. Pick a few points at random and get their labels\n",
    "3. Repeat the following until we have budget left for getting labels\n",
    "    * Fit a classifier/regressor to the labels seen so far\n",
    "    * Pick the BEST unlabeled point to get a label for\n",
    "        — (closest to the boundary?)\n",
    "        — (most uncertain?)\n",
    "        — (most likely to decrease overall uncertainty?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_boston(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_train, X_test, y_full_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_full_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MaxMinDistance**\n",
    "\n",
    "$argmax_{i} d_i$\n",
    "\n",
    "$d_i = min_{x \\in X\\_labeled} ||x_i - x||$ \n",
    "\n",
    "$d_i$ - is minimum distance to labeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxMinDistanceSelector(indices, X_full_train, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    d_min_max = -1\n",
    "    best_new_idx = -1\n",
    "    \n",
    "    for i in range(X_full_train.shape[0]):\n",
    "        \n",
    "        d_min = 1e6\n",
    "        \n",
    "        if i not in indices:\n",
    "            for j in range(X_train.shape[0]):\n",
    "                d = np.linalg.norm(X_full_train[i] - X_train[j])\n",
    "                d_min = min(d, d_min)\n",
    "\n",
    "            if d_min > d_min_max:\n",
    "                best_new_idx = i\n",
    "                d_min_max = d_min\n",
    "        \n",
    "    return best_new_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MaxVarianceSelector**\n",
    "\n",
    "$argmax_{i} \\sigma(x_i | X)$\n",
    "\n",
    "$\\sigma(x_i | X)$ comes from Guassian Process Regression or any bayesian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices - ids of labeled points\n",
    "# X_full_train - all dataset (pool)\n",
    "# X_train - X of labeled points\n",
    "# y_train - y of labeled points\n",
    "# X_test, y_test - test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Implement MaxVarianceSelectorGP, MaxVarianceSelectorBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxVarianceSelectorGP(indices, X_full_train, X_train, y_train, X_test, y_test):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxVarianceSelectorBR(indices, X_full_train, X_train, y_train, X_test, y_test):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_criterion(func):\n",
    "\n",
    "    n_init = 5\n",
    "    indices = list(np.random.choice(N, size = 5, replace = False))\n",
    "    errors = np.zeros(N)\n",
    "    errors[0:n_init] = None\n",
    "\n",
    "    while len(indices) < N:\n",
    "\n",
    "        X_train = X_full_train[indices]\n",
    "        y_train = y_full_train[indices]\n",
    "\n",
    "        best_new_idx = func(indices, X_full_train, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        indices.append(best_new_idx)\n",
    "\n",
    "        #\n",
    "        # Evaluation\n",
    "        #\n",
    "        rf = RandomForestRegressor(n_estimators = 100)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        mean_test = rf.predict(X_test)\n",
    "\n",
    "        rmse = pow(((mean_test - y_test)**2).mean(axis=None), 0.5)\n",
    "        errors[len(indices)-1] = rmse\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = 20\n",
    "\n",
    "error_MaxMinDistance = np.zeros(N)\n",
    "error_MaxVarianceGP = np.zeros(N)\n",
    "error_MaxVarianceBR = np.zeros(N)\n",
    "    \n",
    "for i in range(trials):\n",
    "    error_MaxMinDistance += evaluate_criterion(MaxMinDistanceSelector)\n",
    "    error_MaxVarianceGP += evaluate_criterion(MaxVarianceSelectorGP)\n",
    "    error_MaxVarianceBR += evaluate_criterion(MaxVarianceSelectorBR)\n",
    "    \n",
    "error_MaxMinDistance /= N\n",
    "error_MaxVarianceGP /= N\n",
    "error_MaxVarianceBR /= N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('adoe.pickle', 'wb') as outfile:\n",
    "#    pickle.dump([error_MaxMinDistance, error_MaxVarianceGP, error_MaxVarianceBR], outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged over 20 runs\n",
    "\n",
    "!wget https://raw.githubusercontent.com/adasegroup/ML2020_seminars/master/seminar17/adoe.picklewith\n",
    "    \n",
    "open('adoe.pickle', 'rb') as infile:\n",
    "    [error_MaxMinDistance, error_MaxVarianceGP, error_MaxVarianceBR] = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.plot(range(len(error_MaxMinDistance)), error_MaxMinDistance, label = 'MaxMinDistance')\n",
    "ax = plt.plot(range(len(error_MaxVarianceGP)), error_MaxVarianceGP, label = 'MaxVarianceGP')\n",
    "ax = plt.plot(range(len(error_MaxVarianceBR)), error_MaxVarianceBR, label = 'MaxVarianceBR')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Estimation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.1, 0.5, 0.15, 0.25]\n",
    "\n",
    "ax = plt.bar(range(4), height = p, tick_label = ['p_%d' % i for i in range(4)])\n",
    "plt.ylim((0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Least Confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ SCORE = 1 - {max}_{i} P_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmax(p)\n",
    "unc = [(1-p[i] if i == idx else 0) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.bar(range(4), height = p, tick_label = ['p_%d' % i for i in range(4)])\n",
    "ax = plt.bar(range(4), height = unc, bottom = p)\n",
    "plt.ylim((0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the maximum \"least cofidence\" ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Margin of confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ SCORE = 1 - (P_{i1} - P_{i2})$\n",
    "\n",
    "$P_{i1}, P_{i2}$ - top1 and top2 probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2, idx1 = np.argsort(p)[-2:]\n",
    "margin = p[idx1] - p[idx2]\n",
    "unc = [(margin if i == idx2 else 0) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.bar(range(4), height = p, tick_label = ['p_%d' % i for i in range(4)])\n",
    "ax = plt.bar(range(4), height = unc, bottom = p)\n",
    "plt.ylim((0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the maximum \"margin of cofidence\" ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ SCORE = -\\sum_i P_i \\log P_i $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the maximum \"Entropy\" ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = X[:train_size]\n",
    "y_train_full = np.ndarray.astype(y[:train_size], int)\n",
    "X_test = X[train_size:]\n",
    "y_test = np.ndarray.astype(y[train_size:], int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit_predict(self):\n",
    "        pass\n",
    "\n",
    "class RfModel(BaseModel):\n",
    "\n",
    "    model_type = 'Random Forest'\n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training random forest...')\n",
    "        self.classifier = RandomForestClassifier(n_estimators=100, class_weight=c_weight)\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "\n",
    "    def __init__(self, model_object):        \n",
    "        self.accuracies = []\n",
    "        self.model_object = model_object()        \n",
    "\n",
    "    def print_model_type(self):\n",
    "        print (self.model_object.model_type)\n",
    "\n",
    "    # we train normally and get probabilities for the validation set. i.e., \n",
    "    # we use the probabilities to select the most uncertain samples\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('Train set:', X_train.shape, 'y:', y_train.shape)\n",
    "        print ('Val   set:', X_val.shape)\n",
    "        print ('Test  set:', X_test.shape)\n",
    "        t0 = time.time()\n",
    "        (X_train, X_val, X_test, self.val_y_predicted,\n",
    "         self.test_y_predicted) = \\\n",
    "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
    "        self.run_time = time.time() - t0\n",
    "        return (X_train, X_val, X_test)  # we return them in case we use PCA, with all the other algorithms, this is not needed.\n",
    "\n",
    "    # we want accuracy only for the test set\n",
    "\n",
    "    def get_test_accuracy(self, i, y_test):\n",
    "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
    "        self.accuracies.append(classif_rate)               \n",
    "        print('--------------------------------')\n",
    "        print('Iteration:', i)\n",
    "        print('--------------------------------')\n",
    "        print('y-test set:',y_test.shape)\n",
    "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
    "        print(\"Accuracy rate for %f \" % (classif_rate))    \n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSelectionFunction(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select(self):\n",
    "        pass\n",
    "\n",
    "class RandomSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
    "\n",
    "        return selection\n",
    "\n",
    "class EntropySelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
    "        \n",
    "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
    "        return selection\n",
    "      \n",
    "class RatioSamplingSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
    "        values = rev[:, 0] / rev[:, 1]\n",
    "        selection = np.argsort(values)[:initial_labeled_samples]\n",
    "        return selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Implement MarginSamplingSelection, LeastConfidenceSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginSamplingSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "\n",
    "class LeastConfidenceSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_random_samples(initial_labeled_samples, X_train_full,\n",
    "                         y_train_full):\n",
    "\n",
    "    permutation = np.random.choice(X_train_full.shape[0],\n",
    "                                   initial_labeled_samples,\n",
    "                                   replace=False)\n",
    "    print ()\n",
    "    print ('initial random chosen samples', permutation.shape)\n",
    "\n",
    "    X_train = X_train_full[permutation]\n",
    "    y_train = y_train_full[permutation]\n",
    "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "    bin_count = np.bincount(y_train.astype('int64'))\n",
    "    unique = np.unique(y_train.astype('int64'))\n",
    "    print (\n",
    "        'initial train set:',\n",
    "        X_train.shape,\n",
    "        y_train.shape,\n",
    "        'unique(labels):',\n",
    "        bin_count,\n",
    "        unique,\n",
    "        )\n",
    "    return (permutation, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheAlgorithm(object):\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    def __init__(self, initial_labeled_samples, model_object, selection_function):\n",
    "        self.initial_labeled_samples = initial_labeled_samples\n",
    "        self.model_object = model_object\n",
    "        self.sample_selection_function = selection_function\n",
    "\n",
    "    def run(self, X_train_full, y_train_full, X_test, y_test):\n",
    "\n",
    "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
    "\n",
    "        (permutation, X_train, y_train) = \\\n",
    "            get_k_random_samples(self.initial_labeled_samples,\n",
    "                                 X_train_full, y_train_full)\n",
    "        self.queried = self.initial_labeled_samples\n",
    "        self.samplecount = [self.initial_labeled_samples]\n",
    "\n",
    "        # assign the val set the rest of the 'unlabelled' training data\n",
    "\n",
    "        X_val = np.array([])\n",
    "        y_val = np.array([])\n",
    "        X_val = np.copy(X_train_full)\n",
    "        X_val = np.delete(X_val, permutation, axis=0)\n",
    "        y_val = np.copy(y_train_full)\n",
    "        y_val = np.delete(y_val, permutation, axis=0)\n",
    "        print ('val set:', X_val.shape, y_val.shape, permutation.shape)\n",
    "        print ()\n",
    "\n",
    "        self.clf_model = TrainModel(self.model_object)\n",
    "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "        active_iteration = 1\n",
    "        self.clf_model.get_test_accuracy(1, y_test)\n",
    "\n",
    "        while self.queried < max_queried:\n",
    "\n",
    "            active_iteration += 1\n",
    "\n",
    "            # get validation probabilities\n",
    "\n",
    "            probas_val = \\\n",
    "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
    "            print ('val predicted:',\n",
    "                   self.clf_model.val_y_predicted.shape,\n",
    "                   self.clf_model.val_y_predicted)\n",
    "            print ('probabilities:', probas_val.shape, '\\n',\n",
    "                   np.argmax(probas_val, axis=1))\n",
    "\n",
    "            # select samples using a selection function\n",
    "\n",
    "            uncertain_samples = \\\n",
    "                self.sample_selection_function.select(probas_val, self.initial_labeled_samples)\n",
    "            \n",
    "            print(uncertain_samples)\n",
    "            print(probas_val[uncertain_samples])\n",
    "\n",
    "\n",
    "            # get the uncertain samples from the validation set\n",
    "            print ('trainset before', X_train.shape, y_train.shape)\n",
    "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
    "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
    "            print ('trainset after', X_train.shape, y_train.shape)\n",
    "            self.samplecount.append(X_train.shape[0])\n",
    "\n",
    "            bin_count = np.bincount(y_train.astype('int64'))\n",
    "            \n",
    "            unique = np.unique(y_train.astype('int64'))\n",
    "            print (\n",
    "                'updated train set:',\n",
    "                X_train.shape,\n",
    "                y_train.shape,\n",
    "                'unique(labels):',\n",
    "                bin_count,\n",
    "                unique,\n",
    "                )\n",
    "\n",
    "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
    "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
    "            print ('val set:', X_val.shape, y_val.shape)\n",
    "            print ()\n",
    "\n",
    "            self.queried += self.initial_labeled_samples\n",
    "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
    "\n",
    "        print ('final active learning accuracies',\n",
    "               self.clf_model.accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('train:', X_train_full.shape, y_train_full.shape)\n",
    "print ('test :', X_test.shape, y_test.shape)\n",
    "classes = len(np.unique(y))\n",
    "print ('unique classes', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
    "    algos_temp = []\n",
    "    print ('stopping at:', max_queried)\n",
    "    count = 0\n",
    "    for model_object in models:\n",
    "      if model_object.__name__ not in d:\n",
    "          d[model_object.__name__] = {}\n",
    "      \n",
    "      for selection_function in selection_functions:\n",
    "        if selection_function.__name__ not in d[model_object.__name__]:\n",
    "            d[model_object.__name__][selection_function.__name__] = {}\n",
    "        \n",
    "        for k in Ks:\n",
    "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
    "            \n",
    "            for i in range(0, repeats):\n",
    "                count+=1\n",
    "                if count >= contfrom:\n",
    "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
    "                    alg = TheAlgorithm(k, \n",
    "                                       model_object, \n",
    "                                       selection_function\n",
    "                                       )\n",
    "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
    "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
    "                    fname = 'Active-learning-experiment-' + str(count) + '.pkl'\n",
    "                    #pickle_save(fname, d)\n",
    "                    if count % 5 == 0:\n",
    "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
    "                    print ()\n",
    "                    print ('---------------------------- FINISHED ---------------------------')\n",
    "                    print ()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_queried = 500 \n",
    "repeats = 1\n",
    "\n",
    "models = [RfModel]\n",
    "\n",
    "selection_functions = [RandomSelection, MarginSamplingSelection, RatioSamplingSelection, EntropySelection, LeastConfidenceSelection] \n",
    "\n",
    "MixedSelection\n",
    "\n",
    "Ks = [10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# NB! Execution takes long time\n",
    "#\n",
    "d = {}\n",
    "stopped_at = -1 \n",
    "\n",
    "d = experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
    "print (d)\n",
    "results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'algorithm-upper-bound')\n",
    "    \n",
    "    for model_object in models:\n",
    "      for selection_function in selection_functions:\n",
    "        for idx, k in enumerate(Ks):\n",
    "            x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \n",
    "            Sum = np.array(dic[model_object][selection_function][k][0])\n",
    "            for i in range(1, repeats):\n",
    "                Sum = Sum + np.array(dic[model_object][selection_function][k][i])\n",
    "            mean = Sum / repeats\n",
    "            ax.plot(x, mean, '-', label = model_object + '-' + selection_function + '-' + str(k))\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_xlim([50,500])\n",
    "    ax.set_ylim([40,100])\n",
    "    fig.set_size_inches(15,8)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    ax.set_title('Active Learning Evaluation')\n",
    "    ax.set_xlabel('#samples')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of the experiment, averaged over 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/adasegroup/ML2020_seminars/master/seminar17/active_learning_exp.pickle\n",
    "\n",
    "#with open('active_learning_exp.pickle', 'bw') as outfile:\n",
    "#    pickle.dump(d, outfile)\n",
    "\n",
    "with open('active_learning_exp.pickle', 'rb') as infile:\n",
    "    d = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_str = ['RfModel']\n",
    "selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'RatioSamplingSelection',\\\n",
    "                           'EntropySelection', 'LeastConfidenceSelection']\n",
    "\n",
    "Ks_str = [str(x) for x in Ks] \n",
    "repeats = 10\n",
    "random_forest_upper_bound = 97.\n",
    "total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
    "\n",
    "performance_plot(random_forest_upper_bound, d, models_str, selection_functions_str, Ks_str, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zhu, X., & Ghahramani, Z. (2002). Learning from labeled and unlabeled data with label propagation.\n",
    "\n",
    "*http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Propagation is a semi-supervised machine learning algorithm that assigns labels to previously unlabeled data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/adasegroup/ML2020_seminars/blob/master/seminar17/pic/label-propagation.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) $ w_{ij} = exp(-d_{ij}^2 / \\sigma^2)$ \n",
    "\n",
    "B) $T_{ij} = P(j \\to i) = w_{ij} / \\sum_{k=1}^{N} w_{kj}$\n",
    "\n",
    "C) Y - matrix of class probalities of size N*C \n",
    "\n",
    "D) Smoothing (regularization): $T \\to (1-\\epsilon)T + \\epsilon U$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Propagation Algorithm**:\n",
    "    \n",
    "    Repeat until convergence:\n",
    "1. $Y \\gets TY$\n",
    "2. normalize $Y$ (proper probablity distribution)\n",
    "3. Clamp labeled data (use ground truth labels)\n",
    "\n",
    "The algorithms coverges to the fixed point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import LabelSpreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelPropagation(BaseModel):\n",
    "\n",
    "    model_type = 'LabelProp'\n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        self.classifier = LabelSpreading(gamma=0.25, max_iter=20, kernel = 'knn', n_neighbors = 5)\n",
    "        \n",
    "        X = np.concatenate((X_train, X_val, X_test), axis = 0)\n",
    "        y = np.array([int(y_train[i]) if i < X_train.shape[0] else -1 for i in range(X.shape[0])])\n",
    "        \n",
    "        self.classifier.fit(X, y)\n",
    "        \n",
    "        n1 = X_train.shape[0]\n",
    "        n2 = X_val.shape[0]\n",
    "        n3 = X_test.shape[0]\n",
    "        \n",
    "        self.test_y_predicted = self.classifier.transduction_[range(n1 + n2, n1 + n2 + n3)]\n",
    "        self.val_y_predicted = self.classifier.transduction_[range(n1, n1 + n2)]\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment2(d, models, selection_functions, Ks, repeats, contfrom, X_train_full, y_train_full, X_test, y_test):\n",
    "    algos_temp = []\n",
    "    print ('stopping at:', max_queried)\n",
    "    count = 0\n",
    "    for model_object in models:\n",
    "      if model_object.__name__ not in d:\n",
    "          d[model_object.__name__] = {}\n",
    "      \n",
    "      for selection_function in selection_functions:\n",
    "        if selection_function.__name__ not in d[model_object.__name__]:\n",
    "            d[model_object.__name__][selection_function.__name__] = {}\n",
    "        \n",
    "        for k in Ks:\n",
    "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
    "            \n",
    "            for i in range(0, repeats):\n",
    "                count+=1\n",
    "                if count >= contfrom:\n",
    "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
    "                    alg = TheAlgorithm(k, \n",
    "                                       model_object, \n",
    "                                       selection_function\n",
    "                                       )\n",
    "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
    "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
    "                    fname = 'Active-learning-experiment-' + str(count) + '.pkl'\n",
    "                    #pickle_save(fname, d)\n",
    "                    if count % 5 == 0:\n",
    "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
    "                    print ()\n",
    "                    print ('---------------------------- FINISHED ---------------------------')\n",
    "                    print ()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_queried = 500 \n",
    "repeats = 1\n",
    "\n",
    "models = [LabelPropagation]\n",
    "selection_functions = [RandomSelection, MarginSamplingSelection] \n",
    " \n",
    "Ks = [10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# NB! Execution takes long time\n",
    "#\n",
    "d = {}\n",
    "stopped_at = -1 \n",
    "\n",
    "d = experiment2(d, models, selection_functions, Ks, repeats, stopped_at+1,\\\n",
    "               X_train_full[:1000], y_train_full[:1000], X_test[:1000], y_test[:1000])\n",
    "print (d)\n",
    "results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/adasegroup/ML2020_seminars/master/seminar17/active_learning_exp_label_prop.pickle#with open('active_learning_exp_label_prop.pickle', 'bw') as outfile:\n",
    "#    pickle.dump(d, outfile)\n",
    "\n",
    "with open('active_learning_exp_label_prop.pickle', 'rb') as infile:\n",
    "    d = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_str = ['LabelPropagation']\n",
    "selection_functions_str = ['RandomSelection', 'MarginSamplingSelection']\n",
    "Ks_str = [str(x) for x in Ks] \n",
    "repeats = 10\n",
    "random_forest_upper_bound = 97.\n",
    "total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
    "\n",
    "performance_plot(random_forest_upper_bound, d, models_str, selection_functions_str, Ks_str, 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://github.com/ej0cl6/deep-active-learning\n",
    "\n",
    "**Deep Active Learning**\n",
    "\n",
    "Python implementations of the following active learning algorithms:\n",
    "\n",
    "Random Sampling\n",
    "Least Confidence [1]\n",
    "Margin Sampling [1]\n",
    "Entropy Sampling [1]\n",
    "Uncertainty Sampling with Dropout Estimation [2]\n",
    "Bayesian Active Learning Disagreement [2]\n",
    "K-Means Sampling [3]\n",
    "K-Centers Greedy [3]\n",
    "Core-Set [3]\n",
    "Adversarial - Basic Iterative Method\n",
    "Adversarial - DeepFool [4]\n",
    "\n",
    "[1] A New Active Labeling Method for Deep Learning, IJCNN, 2014\n",
    "[2] Deep Bayesian Active Learning with Image Data, ICML, 2017\n",
    "[3] Active Learning for Convolutional Neural Networks: A Core-Set Approach, ICLR, 2018\n",
    "[4] Adversarial Active Learning for Deep Networks: a Margin Based Approach, arXiv, 2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
